{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from load_dataset import Make_Dataset , train_test_split\n",
    "from word2vec import read_word2vec\n",
    "from trainer import train\n",
    "from inference_function import softmax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dir=\"glove.6B.300d.txt\"\n",
    "csv_path =\"Dataset/Tweets.csv\"\n",
    "\n",
    "maxSequence = 31\n",
    "train_percentage =0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv(csv_path)\n",
    "word_embedding = read_word2vec(word_embedding_dir)  \n",
    "data , labels = Make_Dataset(csv_file,word_embedding,maxSequence)\n",
    "train_data,train_labels,val_data,val_labels = train_test_split(data,labels,train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , Training accuracy:: 0.6617998480796814 , Validation accuracy:: 0.693647563457489 \n",
      "epoch: 1 , Training accuracy:: 0.7677595615386963 , Validation accuracy:: 0.7182376980781555 \n",
      "epoch: 2 , Training accuracy:: 0.8044740557670593 , Validation accuracy:: 0.6970628499984741 \n",
      "epoch: 3 , Training accuracy:: 0.8419569730758667 , Validation accuracy:: 0.6915983557701111 \n",
      "epoch: 4 , Training accuracy:: 0.8712431788444519 , Validation accuracy:: 0.7226775884628296 \n",
      "epoch: 5 , Training accuracy:: 0.891308069229126 , Validation accuracy:: 0.7196038365364075 \n"
     ]
    }
   ],
   "source": [
    "wordembedding_len = list(word_embedding.values())[0].shape[0]\n",
    "numClasses =3\n",
    "num_of_epochs=6\n",
    "batch_size=32\n",
    "train(maxSequence ,wordembedding_len,numClasses,num_of_epochs , batch_size , train_data,train_labels,val_data,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows other evaluation metrics on the validaion dataset and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from Best_model/checkpoint_5.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ckpt/checkpoint_5.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('Best_model/checkpoint_5.ckpt.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('Best_model/'))\n",
    "    \n",
    "    with tf.Session() as sess:    \n",
    "        saver = tf.train.import_meta_graph('ckpt/checkpoint_5.ckpt.meta')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('ckpt/'))\n",
    "\n",
    "        graph = tf.get_default_graph()\n",
    "        input_x = graph.get_tensor_by_name(\"input_data:0\")\n",
    "        keep_prob = graph.get_tensor_by_name(\"keep_prob1:0\")\n",
    "        keep_prob2 = graph.get_tensor_by_name(\"keep_prob2:0\")\n",
    "\n",
    "        op_to_restore = graph.get_tensor_by_name(\"output:0\")\n",
    "\n",
    "\n",
    "        predict =sess.run(op_to_restore,feed_dict={input_x: val_data ,\n",
    "                                    keep_prob:1 ,\n",
    "                                    keep_prob2:1 })\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_classes = softmax(predict).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_classes = val_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the confusion matrix for the three classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 379,   69,  273],\n",
       "       [  92,  311,  120],\n",
       "       [ 179,   88, 1417]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"this is the confusion matrix for the three classes\")\n",
    "confusion_matrix(predict_classes, labels_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6638782330791724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(labels_classes, predict_classes, average='macro')\n",
    "print(\"f1 score: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recal score: 0.6768265885945444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recal = recall_score(labels_classes, predict_classes, average='macro') \n",
    "print(\"recal score: {}\".format(recal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percision score: 0.6539180032797037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "percision = precision_score(labels_classes, predict_classes, average='macro') \n",
    "print(\"percision score: {}\".format(percision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
